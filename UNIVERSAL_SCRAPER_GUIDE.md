# Evrensel Scraper KullanÄ±m KÄ±lavuzu

## ğŸš€ Genel BakÄ±ÅŸ

`UniversalScraper` sÄ±nÄ±fÄ±, farklÄ± e-ticaret sitelerinden Ã¼rÃ¼n verilerini otomatik olarak Ã§ekmek iÃ§in tasarlanmÄ±ÅŸ gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r. Mevcut baÅŸarÄ±lÄ± scraping deneyimlerini analiz ederek oluÅŸturulmuÅŸtur.

## âœ¨ Ã–zellikler

- **AkÄ±llÄ± Site Tespiti**: URL'den otomatik site tespiti
- **Fallback MekanizmalarÄ±**: Birden fazla selector deneme
- **Hata ToleransÄ±**: BaÅŸarÄ±sÄ±z denemelerde alternatif yÃ¶ntemler
- **GeniÅŸletilebilir YapÄ±**: Yeni siteler kolayca eklenebilir
- **Performans Optimizasyonu**: Gereksiz bekleme sÃ¼releri minimize edilmiÅŸ
- **Marka Tespiti**: Otomatik marka tespiti (teknoloji, araba, moda)
- **GÃ¶rsel Kalitesi**: Otomatik gÃ¶rsel kalitesi artÄ±rma

## ğŸ“¦ Kurulum

```bash
pip install playwright
playwright install chromium
```

## ğŸ”§ Temel KullanÄ±m

### Basit KullanÄ±m

```python
from universal_scraper import UniversalScraper

# Scraper oluÅŸtur
scraper = UniversalScraper()

# Tek Ã¼rÃ¼n Ã§ek
url = "https://www.hepsiburada.com/product-url"
result = scraper.scrape_product_sync(url)

if result:
    print(f"BaÅŸlÄ±k: {result['title']}")
    print(f"Fiyat: {result['price']}")
    print(f"Marka: {result['brand']}")
    print(f"GÃ¶rsel: {result['image']}")
    print(f"Site: {result['site']}")
```

### Asenkron KullanÄ±m

```python
import asyncio
from universal_scraper import UniversalScraper

async def main():
    scraper = UniversalScraper()
    
    # Tek Ã¼rÃ¼n
    result = await scraper.scrape_product(url)
    
    # Birden fazla Ã¼rÃ¼n
    urls = ["url1", "url2", "url3"]
    results = await scraper.scrape_multiple_products(urls)

asyncio.run(main())
```

## ğŸ› ï¸ GeliÅŸmiÅŸ KullanÄ±m

### Yeni Site KonfigÃ¼rasyonu Ekleme

```python
scraper = UniversalScraper()

# Yeni site konfigÃ¼rasyonu
new_config = {
    "name": "Yeni Site",
    "selectors": {
        "title": ["h1", ".product-title", "[data-testid='title']"],
        "price": [".price", "span[class*='price']", "[data-testid='price']"],
        "image": ["img[class*='product']", "img[src*='product']", "img"]
    },
    "price_cleaner": scraper._clean_general_price,
    "image_enhancer": scraper._enhance_general_image,
    "brand_detector": scraper._detect_general_brands,
    "wait_time": 3000,
    "timeout": 45000
}

# KonfigÃ¼rasyonu ekle
scraper.add_site_config("yeni-site.com", new_config)
```

### KonfigÃ¼rasyon Kaydetme ve YÃ¼kleme

```python
# KonfigÃ¼rasyonlarÄ± kaydet
scraper.save_configs("my_configs.json")

# Yeni scraper oluÅŸtur ve konfigÃ¼rasyonlarÄ± yÃ¼kle
new_scraper = UniversalScraper()
new_scraper.load_configs("my_configs.json")
```

### Ã–zel Fiyat Temizleme Fonksiyonu

```python
def custom_price_cleaner(price_text):
    """Ã–zel fiyat temizleme fonksiyonu"""
    if not price_text:
        return ""
    
    # Ã–zel temizleme mantÄ±ÄŸÄ±
    price_clean = re.sub(r'[^\d.,]', '', price_text)
    price_clean = price_clean.replace(',', '.')
    
    return price_clean

# KonfigÃ¼rasyona ekle
config["price_cleaner"] = custom_price_cleaner
```

## ğŸ“Š Desteklenen Siteler

### Mevcut KonfigÃ¼rasyonlar

1. **Hepsiburada** (`hepsiburada.com`)
   - Teknoloji Ã¼rÃ¼nleri
   - Ä°ndirimli/indirimsiz fiyat desteÄŸi
   - GÃ¶rsel kalitesi optimizasyonu

2. **Sahibinden** (`sahibinden.com`)
   - AraÃ§ ilanlarÄ±
   - DetaylÄ± Ã¼rÃ¼n bilgileri
   - Ã‡oklu gÃ¶rsel desteÄŸi

3. **Zara** (`zara.com`)
   - Moda Ã¼rÃ¼nleri
   - UluslararasÄ± fiyat desteÄŸi

4. **Mango** (`mango.com`)
   - Moda Ã¼rÃ¼nleri
   - Ã‡oklu dil desteÄŸi

5. **H&M** (`hm.com`)
   - Moda Ã¼rÃ¼nleri
   - Global site desteÄŸi

### Bilinmeyen Siteler

Bilinmeyen siteler iÃ§in otomatik genel selector'lar kullanÄ±lÄ±r:
- AkÄ±llÄ± baÅŸlÄ±k arama
- Para birimi bazlÄ± fiyat arama
- ÃœrÃ¼n gÃ¶rseli tespiti

## ğŸ¯ Marka Tespiti

### Desteklenen Marka Kategorileri

1. **Teknoloji MarkalarÄ±**
   - Apple, Samsung, Xiaomi, Huawei, vb.
   - Bilgisayar parÃ§alarÄ± (Intel, AMD, NVIDIA, vb.)
   - Aksesuarlar (Logitech, Razer, vb.)

2. **Araba MarkalarÄ±**
   - Lada, BMW, Mercedes, Audi, vb.
   - TÃ¼rk ve uluslararasÄ± markalar

3. **Moda MarkalarÄ±**
   - Zara, Mango, H&M, vb.
   - LÃ¼ks markalar (Gucci, Prada, vb.)

## âš™ï¸ KonfigÃ¼rasyon Parametreleri

### Site KonfigÃ¼rasyonu YapÄ±sÄ±

```python
{
    "name": "Site AdÄ±",
    "selectors": {
        "title": ["selector1", "selector2", "selector3"],
        "price": ["price_selector1", "price_selector2"],
        "image": ["image_selector1", "image_selector2"],
        "original_price": ["original_price_selector"],  # Opsiyonel
        "description": ["description_selector"]  # Opsiyonel
    },
    "price_cleaner": function,  # Fiyat temizleme fonksiyonu
    "image_enhancer": function,  # GÃ¶rsel kalitesi artÄ±rma fonksiyonu
    "brand_detector": function,  # Marka tespit fonksiyonu
    "wait_time": 3000,  # Sayfa yÃ¼kleme bekleme sÃ¼resi (ms)
    "timeout": 45000    # Maksimum timeout sÃ¼resi (ms)
}
```

### Selector Stratejileri

1. **Spesifik Selector'lar**: Site Ã¶zel selector'lar
2. **Genel Selector'lar**: Bilinmeyen siteler iÃ§in
3. **AkÄ±llÄ± Arama**: Otomatik element tespiti

## ğŸ” Hata YÃ¶netimi

### Retry MekanizmasÄ±

```python
# VarsayÄ±lan: 3 deneme
result = scraper.scrape_product_sync(url, max_retries=3)

# Ã–zel deneme sayÄ±sÄ±
result = scraper.scrape_product_sync(url, max_retries=5)
```

### Hata TÃ¼rleri

1. **Network HatasÄ±**: BaÄŸlantÄ± sorunlarÄ±
2. **Selector HatasÄ±**: Element bulunamadÄ±
3. **Timeout HatasÄ±**: Sayfa yÃ¼kleme zaman aÅŸÄ±mÄ±
4. **Rate Limiting**: Ã‡ok fazla istek

## ğŸ“ˆ Performans Optimizasyonu

### TarayÄ±cÄ± OptimizasyonlarÄ±

- GÃ¶rsel ve CSS dosyalarÄ± engellenir
- GPU hÄ±zlandÄ±rma devre dÄ±ÅŸÄ±
- Sandbox gÃ¼venlik ayarlarÄ±
- Bellek kullanÄ±mÄ± optimize edilmiÅŸ

### Rate Limiting

```python
# Otomatik rate limiting
results = await scraper.scrape_multiple_products(urls)

# Manuel bekleme
import time
for url in urls:
    result = scraper.scrape_product_sync(url)
    time.sleep(2)  # 2 saniye bekle
```

## ğŸ§ª Test Etme

### Test DosyasÄ± Ã‡alÄ±ÅŸtÄ±rma

```bash
python test_universal_scraper.py
```

### Ã–zel Test

```python
from universal_scraper import UniversalScraper

scraper = UniversalScraper()

# Test URL'leri
test_urls = [
    "https://www.hepsiburada.com/product1",
    "https://www.sahibinden.com/ilan1",
    "https://www.zara.com/product1"
]

# Test et
for url in test_urls:
    result = scraper.scrape_product_sync(url)
    print(f"URL: {url}")
    print(f"BaÅŸarÄ±lÄ±: {result is not None}")
    if result:
        print(f"Site: {result['site']}")
        print(f"BaÅŸlÄ±k: {result['title'][:50]}...")
```

## ğŸ”§ Sorun Giderme

### YaygÄ±n Sorunlar

1. **Element BulunamadÄ±**
   - Selector'larÄ± gÃ¼ncelleyin
   - Sayfa yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir
   - AkÄ±llÄ± arama kullanÄ±n

2. **YavaÅŸ Performans**
   - Timeout deÄŸerlerini artÄ±rÄ±n
   - Rate limiting ekleyin
   - GÃ¶rsel yÃ¼klemeyi devre dÄ±ÅŸÄ± bÄ±rakÄ±n

3. **HatalÄ± Veri**
   - Fiyat temizleme fonksiyonunu kontrol edin
   - Marka tespitini doÄŸrulayÄ±n
   - Selector'larÄ± test edin

### Debug Modu

```python
import logging
logging.basicConfig(level=logging.DEBUG)

scraper = UniversalScraper()
result = scraper.scrape_product_sync(url)
```

## ğŸ“ Ã–rnek KullanÄ±m SenaryolarÄ±

### Senaryo 1: E-ticaret Fiyat Takibi

```python
scraper = UniversalScraper()

# ÃœrÃ¼n listesi
products = [
    "https://www.hepsiburada.com/product1",
    "https://www.sahibinden.com/product2",
    "https://www.zara.com/product3"
]

# FiyatlarÄ± kontrol et
for url in products:
    result = scraper.scrape_product_sync(url)
    if result:
        print(f"{result['title']}: {result['price']} TL")
```

### Senaryo 2: Marka Analizi

```python
scraper = UniversalScraper()

# FarklÄ± sitelerden aynÄ± marka Ã¼rÃ¼nleri
brand_urls = [
    "https://site1.com/apple-iphone",
    "https://site2.com/apple-iphone",
    "https://site3.com/apple-iphone"
]

# Marka karÅŸÄ±laÅŸtÄ±rmasÄ±
for url in brand_urls:
    result = scraper.scrape_product_sync(url)
    if result and result['brand'] == 'APPLE':
        print(f"{result['site']}: {result['price']}")
```

### Senaryo 3: Yeni Site Entegrasyonu

```python
scraper = UniversalScraper()

# Yeni site iÃ§in test
test_url = "https://yeni-site.com/product/123"

# Ã–nce genel selector'larla test et
result = scraper.scrape_product_sync(test_url)

if result:
    print("Genel selector'lar Ã§alÄ±ÅŸÄ±yor!")
    
    # Ã–zel konfigÃ¼rasyon ekle
    custom_config = {
        "name": "Yeni Site",
        "selectors": {
            "title": ["h1.product-title"],
            "price": [".product-price"],
            "image": ["img.product-image"]
        },
        "price_cleaner": scraper._clean_general_price,
        "image_enhancer": scraper._enhance_general_image,
        "brand_detector": scraper._detect_general_brands,
        "wait_time": 2000,
        "timeout": 30000
    }
    
    scraper.add_site_config("yeni-site.com", custom_config)
    scraper.save_configs()
```

## ğŸ“š API ReferansÄ±

### UniversalScraper SÄ±nÄ±fÄ±

#### Metodlar

- `scrape_product(url, max_retries=3)`: Asenkron Ã¼rÃ¼n Ã§ekme
- `scrape_product_sync(url, max_retries=3)`: Senkron Ã¼rÃ¼n Ã§ekme
- `scrape_multiple_products(urls, max_retries=3)`: Toplu Ã¼rÃ¼n Ã§ekme
- `add_site_config(domain, config)`: Yeni site konfigÃ¼rasyonu ekleme
- `save_configs(filename)`: KonfigÃ¼rasyonlarÄ± kaydetme
- `load_configs(filename)`: KonfigÃ¼rasyonlarÄ± yÃ¼kleme

#### DÃ¶nen Veri YapÄ±sÄ±

```python
{
    "title": "ÃœrÃ¼n BaÅŸlÄ±ÄŸÄ±",
    "price": "123.45",
    "image": "https://example.com/image.jpg",
    "brand": "MARKA_ADI",
    "url": "https://example.com/product",
    "site": "Site AdÄ±",
    "scraped_at": "2024-01-01 12:00:00",
    "original_price": "150.00"  # Opsiyonel (Hepsiburada)
}
```

## ğŸ¤ KatkÄ±da Bulunma

1. Yeni site konfigÃ¼rasyonlarÄ± ekleyin
2. Selector'larÄ± gÃ¼ncelleyin
3. Test senaryolarÄ± ekleyin
4. Performans iyileÅŸtirmeleri yapÄ±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.
